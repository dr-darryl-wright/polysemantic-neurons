{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57957dd",
   "metadata": {},
   "source": [
    "# It looks like lucid only works with 2d 3 channel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509d8425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dwright/anaconda2/envs/local_specialization/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import lucid\n",
    "import itertools\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import lucid.optvis.render as render\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from lucid.modelzoo.vision_models import Model\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "# sys.path.insert(0, '../clusterability_in_neural_networks/')\n",
    "# from src import lucid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3104ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef594bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_neurons = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8413824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 08:22:52.769253: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-06-07 08:22:52.788580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ee39ca050 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-06-07 08:22:52.788605: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "i_save = tf.keras.layers.Input(shape=(28*28,3), name='input')\n",
    "e1_save = tf.keras.layers.Dense(n_hidden_neurons, activation='relu', name='dense_1')(i_save)\n",
    "e2_save = tf.keras.layers.Dense(n_hidden_neurons, activation='relu', name='dense_2')(e1_save)\n",
    "e3_save = tf.keras.layers.Dense(n_hidden_neurons, activation='relu', name='dense_3')(e2_save)\n",
    "e4_save = tf.keras.layers.Dense(n_hidden_neurons, activation='relu', name='dense_4')(e3_save)\n",
    "o_save = tf.keras.layers.Dense(10, activation='softmax', name='softmax')(e4_save)\n",
    "model = tf.keras.Model(inputs=i_save, outputs=o_save)\n",
    "\n",
    "model.load_weights('/Users/dwright/dev/P3/polysemantic-neurons/experiments/mnist/alpha_1.0/trial_1/inference_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacca8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 08:22:53.065708: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n",
      "2022-06-07 08:22:53.065781: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2022-06-07 08:22:53.067326: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
      "2022-06-07 08:22:53.067348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "2022-06-07 08:22:53.067354: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Frozen model layers: \n",
      "x\n",
      "model/dense_1/MatMul/ReadVariableOp/resource\n",
      "model/dense_1/MatMul/ReadVariableOp\n",
      "model/dense_1/MatMul\n",
      "model/dense_1/BiasAdd/ReadVariableOp/resource\n",
      "model/dense_1/BiasAdd/ReadVariableOp\n",
      "model/dense_1/BiasAdd\n",
      "model/dense_1/Relu\n",
      "model/dense_2/MatMul/ReadVariableOp/resource\n",
      "model/dense_2/MatMul/ReadVariableOp\n",
      "model/dense_2/MatMul\n",
      "model/dense_2/BiasAdd/ReadVariableOp/resource\n",
      "model/dense_2/BiasAdd/ReadVariableOp\n",
      "model/dense_2/BiasAdd\n",
      "model/dense_2/Relu\n",
      "model/dense_3/MatMul/ReadVariableOp/resource\n",
      "model/dense_3/MatMul/ReadVariableOp\n",
      "model/dense_3/MatMul\n",
      "model/dense_3/BiasAdd/ReadVariableOp/resource\n",
      "model/dense_3/BiasAdd/ReadVariableOp\n",
      "model/dense_3/BiasAdd\n",
      "model/dense_3/Relu\n",
      "model/dense_4/MatMul/ReadVariableOp/resource\n",
      "model/dense_4/MatMul/ReadVariableOp\n",
      "model/dense_4/MatMul\n",
      "model/dense_4/BiasAdd/ReadVariableOp/resource\n",
      "model/dense_4/BiasAdd/ReadVariableOp\n",
      "model/dense_4/BiasAdd\n",
      "model/dense_4/Relu\n",
      "model/softmax/MatMul/ReadVariableOp/resource\n",
      "model/softmax/MatMul/ReadVariableOp\n",
      "model/softmax/MatMul\n",
      "model/softmax/BiasAdd/ReadVariableOp/resource\n",
      "model/softmax/BiasAdd/ReadVariableOp\n",
      "model/softmax/BiasAdd\n",
      "model/softmax/Softmax\n",
      "Identity\n",
      "------------------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'x:0' shape=(?, 784) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(?, 10) dtype=float32>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/dwright/dev/P3/polysemantic-neurons/experiments/mnist/alpha_1.0/trial_1/inference_model_frozen_graph.pbtxt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://medium.com/@sebastingarcaacosta/how-to-export-a-tensorflow-2-x-keras-model-to-a-frozen-and-optimized-graph-39740846d9eb\n",
    "frozen_out_path = '/Users/dwright/dev/P3/polysemantic-neurons/experiments/mnist/alpha_1.0/trial_1/'\n",
    "frozen_graph_filename = 'inference_model_frozen_graph'\n",
    "\n",
    "# Convert Keras model to ConcreteFunction\n",
    "full_model = tf.function(lambda x: model(x))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    "\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "frozen_func.graph.as_graph_def()\n",
    "\n",
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 60)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)\n",
    "    \n",
    "# Save frozen graph to disk\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=frozen_out_path,\n",
    "                  name=f\"{frozen_graph_filename}.pb\",\n",
    "                  as_text=False)\n",
    "# Save its text representation\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=frozen_out_path,\n",
    "                  name=f\"{frozen_graph_filename}.pbtxt\",\n",
    "                  as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36abffb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'import/x' type=Placeholder>, <tf.Operation 'import/model/dense_1/MatMul/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/dense_1/MatMul/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/dense_1/MatMul' type=MatMul>, <tf.Operation 'import/model/dense_1/BiasAdd/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/dense_1/BiasAdd/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/dense_1/BiasAdd' type=BiasAdd>, <tf.Operation 'import/model/dense_1/Relu' type=Relu>, <tf.Operation 'import/model/dense_2/MatMul/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/dense_2/MatMul/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/dense_2/MatMul' type=MatMul>, <tf.Operation 'import/model/dense_2/BiasAdd/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/dense_2/BiasAdd/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/dense_2/BiasAdd' type=BiasAdd>, <tf.Operation 'import/model/dense_2/Relu' type=Relu>, <tf.Operation 'import/model/dense_3/MatMul/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/dense_3/MatMul/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/dense_3/MatMul' type=MatMul>, <tf.Operation 'import/model/dense_3/BiasAdd/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/dense_3/BiasAdd/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/dense_3/BiasAdd' type=BiasAdd>, <tf.Operation 'import/model/dense_3/Relu' type=Relu>, <tf.Operation 'import/model/dense_4/MatMul/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/dense_4/MatMul/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/dense_4/MatMul' type=MatMul>, <tf.Operation 'import/model/dense_4/BiasAdd/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/dense_4/BiasAdd/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/dense_4/BiasAdd' type=BiasAdd>, <tf.Operation 'import/model/dense_4/Relu' type=Relu>, <tf.Operation 'import/model/softmax/MatMul/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/softmax/MatMul/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/softmax/MatMul' type=MatMul>, <tf.Operation 'import/model/softmax/BiasAdd/ReadVariableOp/resource' type=Const>, <tf.Operation 'import/model/softmax/BiasAdd/ReadVariableOp' type=Identity>, <tf.Operation 'import/model/softmax/BiasAdd' type=BiasAdd>, <tf.Operation 'import/model/softmax/Softmax' type=Softmax>, <tf.Operation 'import/Identity' type=Identity>]\n",
      "Inferred: input_name = import/x (because it was the only Placeholder in the graph_def)\n",
      "Inferred: output_names = ['import/model/softmax/Softmax']  (because those are all the Softmax ops)\n",
      "# Please sanity check all inferred values before using this code.\n",
      "# Incorrect `image_value_range` is the most common cause of feature visualization bugs! Most methods will fail silently with incorrect visualizations!\n",
      "Model.save(\n",
      "    input_name='import/x',\n",
      "    image_shape=_,                   # TODO (eg. [224, 224, 3])\n",
      "    output_names=['import/model/softmax/Softmax'],\n",
      "    image_value_range=_,                   # TODO (eg. '[-1, 1], [0, 1], [0, 255], or [-117, 138]')\n",
      "  )\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph, tf.Session() as sess:\n",
    "    #images = tf.placeholder('float32', [None, 784], name='input')\n",
    "            \n",
    "    with tf.io.gfile.GFile(os.path.join(frozen_out_path, \n",
    "                                f'{frozen_graph_filename}.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    #nodes = [n.name + ' => ' +  n.op for n in graph_def.node if n.op in ('Placeholder')]\n",
    "    #tf.import_graph_def(graph_def, input_map={'^x': images})\n",
    "    tf.import_graph_def(graph_def)\n",
    "    print(sess.graph.get_operations())\n",
    "    model = Model()\n",
    "    model.load_graphdef()\n",
    "    model.suggest_save_args()\n",
    "    model.save(os.path.join(frozen_out_path, 'lucid_model_save.pb'),\n",
    "               input_name='import/x',\n",
    "               image_shape=(784,1),\n",
    "               image_value_range=[0,1],\n",
    "               output_names=['import/model/softmax/Softmax']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72ec3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load(os.path.join(frozen_out_path, 'lucid_model_save.pb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf85dfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 4 for 'import/import/model/dense_1/MatMul' (op: 'MatMul') with input shapes: [1,?,?,3], [784,256].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/local_specialization/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[0;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    500\u001b[0m         results = c_api.TF_GraphImportGraphDefWithResults(\n\u001b[0;32m--> 501\u001b[0;31m             graph._c_graph, serialized, options)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopedTFImportGraphDefResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 2 but is rank 4 for 'import/import/model/dense_1/MatMul' (op: 'MatMul') with input shapes: [1,?,?,3], [784,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v4/sv47xgds2v5gnrw03x00sysc0000gr/T/ipykernel_55992/1565002660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dense_1:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/local_specialization/lib/python3.7/site-packages/lucid/optvis/render.py\u001b[0m in \u001b[0;36mrender_vis\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, thresholds, print_objectives, verbose, relu_gradient_override, use_fixed_seed)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     T = make_vis_T(model, objective_f, param_f, optimizer, transforms,\n\u001b[0;32m---> 95\u001b[0;31m                    relu_gradient_override)\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mprint_objective_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_print_objective_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_objectives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vis_op\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/local_specialization/lib/python3.7/site-packages/lucid/optvis/render.py\u001b[0m in \u001b[0;36mmake_vis_T\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, relu_gradient_override)\u001b[0m\n\u001b[1;32m    175\u001b[0m     with gradient_override_map({'Relu': redirected_relu_grad,\n\u001b[1;32m    176\u001b[0m                                 'Relu6': redirected_relu6_grad}):\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/local_specialization/lib/python3.7/site-packages/lucid/optvis/render.py\u001b[0m in \u001b[0;36mimport_model\u001b[0;34m(model, t_image, t_image_raw, scope, input_map)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mt_image_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m   \u001b[0mT_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforget_xy_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/local_specialization/lib/python3.7/site-packages/lucid/modelzoo/vision_base.py\u001b[0m in \u001b[0;36mimport_graph\u001b[0;34m(self, t_input, scope, forget_xy_shape, input_map)\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mfinal_input_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     tf.import_graph_def(\n\u001b[0;32m--> 201\u001b[0;31m         self.graph_def, final_input_map, name=scope)\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/local_specialization/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda2/envs/local_specialization/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[0;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    403\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m       \u001b[0mop_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m       producer_op_list=producer_op_list)\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/local_specialization/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[0;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    503\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# Create _DefinedFunctions for any imported functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 2 but is rank 4 for 'import/import/model/dense_1/MatMul' (op: 'MatMul') with input shapes: [1,?,?,3], [784,256]."
     ]
    }
   ],
   "source": [
    "render.render_vis(model, 'dense_1:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec69b2",
   "metadata": {},
   "source": [
    "The above seems to imply 2d images with 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c63ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
